---
title: Artifical Typist-Touchscreen Typing As Optimal Supervisory Control
summary: This project presents a computational model of how people type on touch-screen keyboards. We explaore the role of visual attention being shared between the keyboard and the text area. 
tags:
date:

# Optional external URL for project (replaces project detail page).
external_link: ""

image:
  caption:
  focal_point: Smart

links:
url_code: "https://github.com/aditya02acharya/TypingAgent"
url_pdf: ""
url_slides: ""
url_video: "media/typist.mp4"

# Slides (optional).
#   Associate this project with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides: example
---

Touchscreen typing has been traditionally studied in terms of motor performance. However, recent research exposed a decisive role ofvisual attention being shared between the keyboard and the text area. Strategies for this are known to adapt to the task, design, anduser. In this paper, we propose a unifying account of touchscreen typing, regarding it as optimal supervisory control. This assumes thatdecisions on controlling visuo-motor resources are learned via exploration, and made to maximise typing performance. We outline thetheory and explain how visual and motor bounds affect this control problem. We then present a model, implemented via reinforcementlearning, simulating coordination of eye and finger movements. Comparison with human data affirms that the model creates realistic,interlinked finger- and eye-movement patterns. We demonstrate the modelâ€™s use in interface development to evaluate touchscreenkeyboard designs.
